{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, root_mean_squared_error\n",
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from pygam import LinearGAM\n",
    "import numpy as np\n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_split_train_data(train_file, target_column, id_column):\n",
    "    data = pd.read_csv(train_file)\n",
    "    ids = data[id_column]  # Keep the id column for reference\n",
    "    X = data.drop(\n",
    "        [target_column, id_column], axis=1\n",
    "    )  # Drop target and id from features\n",
    "    y = data[target_column]  # Target\n",
    "\n",
    "    # Split into 70% training, 15% validation, 15% test\n",
    "    X_train, X_temp, y_train, y_temp, ids_train, ids_temp = train_test_split(\n",
    "        X, y, ids, test_size=0.3, random_state=42\n",
    "    )\n",
    "    X_val, X_test, y_val, y_test, ids_val, ids_test = train_test_split(\n",
    "        X_temp, y_temp, ids_temp, test_size=0.5, random_state=42\n",
    "    )\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test, ids_train, ids_val, ids_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_data(test_file, id_column):\n",
    "    data = pd.read_csv(test_file)\n",
    "    ids = data[id_column]  # Keep id for reference\n",
    "    X_test = data.drop(id_column, axis=1)  # Drop id from features\n",
    "    return X_test, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_search_spaces():\n",
    "    search_spaces = {\n",
    "        \"LightGBM\": {\n",
    "            \"pipeline\": Pipeline(\n",
    "                [\n",
    "                    (\n",
    "                        \"feature_selection\",\n",
    "                        RFECV(estimator=lgb.LGBMRegressor(), step=1, cv=KFold(5)),\n",
    "                    ),\n",
    "                    (\"regressor\", lgb.LGBMRegressor()),\n",
    "                ]\n",
    "            ),\n",
    "            \"space\": {\n",
    "                \"regressor__num_leaves\": hp.choice(\n",
    "                    \"regressor__num_leaves\", np.arange(2, 50 + 1, dtype=int)\n",
    "                ),\n",
    "                \"regressor__learning_rate\": hp.uniform(\n",
    "                    \"regressor__learning_rate\", 0.01, 0.3\n",
    "                ),\n",
    "                \"regressor__n_estimators\": hp.choice(\n",
    "                    \"regressor__n_estimators\",\n",
    "                    np.arange(100, 250 + 1, dtype=int),  # değiştirildi\n",
    "                ),\n",
    "                \"regressor__max_depth\": hp.choice(\n",
    "                    \"regressor__max_depth\", np.arange(3, 15 + 1, dtype=int)\n",
    "                ),\n",
    "                \"regressor__min_child_samples\": hp.choice(\n",
    "                    \"regressor__min_child_samples\", np.arange(5, 30 + 1, dtype=int)\n",
    "                ),\n",
    "            },\n",
    "        },\n",
    "        \"XGBoost\": {\n",
    "            \"pipeline\": Pipeline(\n",
    "                [\n",
    "                    (\n",
    "                        \"feature_selection\",\n",
    "                        RFECV(estimator=xgb.XGBRegressor(), step=1, cv=KFold(5)),\n",
    "                    ),\n",
    "                    (\"regressor\", xgb.XGBRegressor()),\n",
    "                ]\n",
    "            ),\n",
    "            \"space\": {\n",
    "                \"regressor__max_depth\": hp.choice(\n",
    "                    \"regressor__max_depth\", np.arange(3, 10, dtype=int)\n",
    "                ),\n",
    "                \"regressor__learning_rate\": hp.uniform(\n",
    "                    \"regressor__learning_rate\", 0.01, 0.3\n",
    "                ),\n",
    "                \"regressor__n_estimators\": hp.choice(\n",
    "                    \"regressor__n_estimators\", np.arange(100, 1000 + 1, dtype=int)\n",
    "                ),\n",
    "                \"regressor__min_child_weight\": hp.quniform(\n",
    "                    \"regressor__min_child_weight\", 1, 10, 1\n",
    "                ),\n",
    "                \"regressor__gamma\": hp.uniform(\"regressor__gamma\", 0, 5),  # gamma >= 0\n",
    "            },\n",
    "        },\n",
    "        \"Ridge\": {\n",
    "            \"pipeline\": Pipeline(\n",
    "                [\n",
    "                    (\n",
    "                        \"feature_selection\",\n",
    "                        RFECV(estimator=Ridge(), step=1, cv=KFold(5)),\n",
    "                    ),\n",
    "                    (\"regressor\", Ridge()),\n",
    "                ]\n",
    "            ),\n",
    "            \"space\": {\n",
    "                \"regressor__alpha\": hp.loguniform(\n",
    "                    \"regressor__alpha\", np.log(0.001), np.log(100)\n",
    "                )\n",
    "            },\n",
    "        },\n",
    "        \"GAM\": {\n",
    "            \"pipeline\": Pipeline(\n",
    "                [\n",
    "                    (\n",
    "                        \"feature_selection\",\n",
    "                        SelectKBest(score_func=f_regression),\n",
    "                    ),\n",
    "                    (\"regressor\", LinearGAM()),\n",
    "                ]\n",
    "            ),\n",
    "            \"space\": {\n",
    "                \"feature_selection__k\": hp.choice(\n",
    "                    \"feature_selection__k\", np.arange(5, 25 + 1, dtype=int)\n",
    "                ),\n",
    "                \"regressor__lam\": hp.loguniform(\n",
    "                    \"regressor__lam\", np.log(0.01), np.log(10)\n",
    "                ),\n",
    "                \"regressor__n_splines\": hp.quniform(\"regressor__n_splines\", 10, 50, 1),\n",
    "            },\n",
    "        },\n",
    "        \"CatBoost\": {\n",
    "            \"pipeline\": Pipeline(\n",
    "                [\n",
    "                    (\n",
    "                        \"feature_selection\",\n",
    "                        SelectKBest(score_func=f_regression),\n",
    "                    ),\n",
    "                    (\n",
    "                        \"regressor\",\n",
    "                        CatBoostRegressor(\n",
    "                            verbose=100,\n",
    "                            early_stopping_rounds=50,\n",
    "                        ),\n",
    "                    ),\n",
    "                ]\n",
    "            ),\n",
    "            \"space\": {\n",
    "                \"feature_selection__k\": hp.choice(\n",
    "                    \"feature_selection__k\", np.arange(5, 25 + 1, dtype=int)\n",
    "                ),\n",
    "                \"regressor__depth\": hp.choice(\n",
    "                    \"regressor__depth\", np.arange(3, 10 + 1, dtype=int)\n",
    "                ),\n",
    "                \"regressor__learning_rate\": hp.uniform(\n",
    "                    \"regressor__learning_rate\", 0.01, 0.3\n",
    "                ),\n",
    "                \"regressor__n_estimators\": hp.choice(\n",
    "                    \"regressor__n_estimators\", np.arange(100, 1000, dtype=int)\n",
    "                ),\n",
    "                \"regressor__l2_leaf_reg\": hp.uniform(\"regressor__l2_leaf_reg\", 1, 10),\n",
    "                \"regressor__bagging_temperature\": hp.uniform(\n",
    "                    \"regressor__bagging_temperature\", 0, 1\n",
    "                ),\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "    return search_spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective function for HyperOpt\n",
    "def objective(params, model_name, X_train, y_train, X_val, y_val):\n",
    "    model_data = get_search_spaces()[model_name]\n",
    "    pipeline = model_data[\"pipeline\"].set_params(**params)\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    val_pred = pipeline.predict(X_val)\n",
    "    rmse = root_mean_squared_error(y_val, val_pred)\n",
    "    return {\"loss\": rmse, \"status\": STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HyperOpt optimization\n",
    "def hyperopt_optimization(X_train, y_train, X_val, y_val):\n",
    "    best_models = {}\n",
    "    search_spaces = get_search_spaces()\n",
    "\n",
    "    for model_name, model_data in search_spaces.items():\n",
    "        print(f\"Optimizing {model_name}...\")\n",
    "        trials = Trials()\n",
    "        best_params = fmin(\n",
    "            fn=lambda params: objective(\n",
    "                params, model_name, X_train, y_train, X_val, y_val\n",
    "            ),\n",
    "            space=model_data[\"space\"],\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=50,\n",
    "            trials=trials,\n",
    "        )\n",
    "        best_models[model_name] = best_params\n",
    "        print(f\"Best params for {model_name}: {best_params}\")\n",
    "\n",
    "    return best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_best_model(best_params, model_name, X_train, y_train, X_test, y_test):\n",
    "    search_spaces = get_search_spaces()\n",
    "    pipeline = search_spaces[model_name][\"pipeline\"].set_params(**best_params)\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    test_pred = pipeline.predict(X_test)\n",
    "    test_rmse = root_mean_squared_error(y_test, test_pred)\n",
    "    print(f\"Test RMSE for {model_name}: {test_rmse}\")\n",
    "    return test_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify predict_on_test_data to keep ids and merge with predictions\n",
    "def predict_on_test_data(\n",
    "    best_params, model_name, X_train, y_train, test_data, test_ids\n",
    "):\n",
    "    search_spaces = get_search_spaces()\n",
    "    pipeline = search_spaces[model_name][\"pipeline\"].set_params(**best_params)\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    predictions = pipeline.predict(test_data)\n",
    "    # Create a DataFrame to store ids and predictions\n",
    "    predictions_df = pd.DataFrame({\"id\": test_ids, \"Predictions\": predictions})\n",
    "    return predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and split train.csv\n",
    "dataset_address = \"./datathon-dataset/processed-data/train_data_cleaned.csv\"\n",
    "target_column = \"degerlendirme_puani\"\n",
    "test_dataset_address = \"./datathon-dataset/processed-data/test_data_cleaned.csv\"\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, ids_train, ids_val, ids_test = (\n",
    "    load_and_split_train_data(dataset_address, target_column, \"id\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing Ridge...\n",
      "100%|██████████| 50/50 [01:02<00:00,  1.24s/trial, best loss: 8.77262349419707] \n",
      "Best params for Ridge: {'regressor__alpha': 97.02651413141194}\n",
      "Optimizing GAM...\n",
      "100%|██████████| 50/50 [03:02<00:00,  3.65s/trial, best loss: 7.5553384831467545]\n",
      "Best params for GAM: {'feature_selection__k': 20, 'regressor__lam': 0.01724780874664662, 'regressor__n_splines': 12.0}\n"
     ]
    }
   ],
   "source": [
    "# Optimize using HyperOpt\n",
    "best_models = hyperopt_optimization(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Ridge on test set...\n",
      "Test RMSE for Ridge: 8.841124040674602\n",
      "\n",
      "Evaluating GAM on test set...\n",
      "Test RMSE for GAM: 7.5463824425387305\n",
      "\n",
      "Best model is GAM with RMSE: 7.5463824425387305\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the best models on the test set\n",
    "best_model_name = None\n",
    "best_rmse = float(\"inf\")\n",
    "for model_name, best_params in best_models.items():\n",
    "    print(f\"\\nEvaluating {model_name} on test set...\")\n",
    "    rmse = test_best_model(best_params, model_name, X_train, y_train, X_test, y_test)\n",
    "    if rmse < best_rmse:\n",
    "        best_rmse = rmse\n",
    "        best_model_name = model_name\n",
    "\n",
    "print(f\"\\nBest model is {best_model_name} with RMSE: {best_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data, test_ids = load_test_data(test_dataset_address, \"id\")\n",
    "best_params = best_models[best_model_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>basvuru_yili</th>\n",
       "      <th>cinsiyet</th>\n",
       "      <th>dogum_yeri</th>\n",
       "      <th>ikametgah_sehri</th>\n",
       "      <th>universite_adi</th>\n",
       "      <th>universite_turu</th>\n",
       "      <th>burslu_ise_burs_yuzdesi</th>\n",
       "      <th>burs_aliyor_mu?</th>\n",
       "      <th>bölüm</th>\n",
       "      <th>...</th>\n",
       "      <th>anne_calisma_durumu</th>\n",
       "      <th>anne_sektor</th>\n",
       "      <th>baba_egitim_durumu</th>\n",
       "      <th>baba_calisma_durumu</th>\n",
       "      <th>baba_sektor</th>\n",
       "      <th>kardes_sayisi</th>\n",
       "      <th>ingilizce_biliyor_musunuz?</th>\n",
       "      <th>ingilizce_seviyeniz?</th>\n",
       "      <th>dogum_yili</th>\n",
       "      <th>dogum_ayi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>199.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>347.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2002</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>432.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2004</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2023</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>179.0</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>44.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2002</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2023</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>171.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2003</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2023</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>34</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11044</th>\n",
       "      <td>11044</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>6</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11045</th>\n",
       "      <td>11045</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2001</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11046</th>\n",
       "      <td>11046</td>\n",
       "      <td>2023</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>146.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2004</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11047</th>\n",
       "      <td>11047</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2001</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11048</th>\n",
       "      <td>11048</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>6</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1999</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11049 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  basvuru_yili  cinsiyet  dogum_yeri  ikametgah_sehri  \\\n",
       "0               0          2023         1           5                5   \n",
       "1               1          2023         1          42               42   \n",
       "2               2          2023         0          34               34   \n",
       "3               3          2023         0          47               47   \n",
       "4               4          2023         0          55               34   \n",
       "...           ...           ...       ...         ...              ...   \n",
       "11044       11044          2023         1          66                6   \n",
       "11045       11045          2023         1          42               42   \n",
       "11046       11046          2023         0           6                6   \n",
       "11047       11047          2023         1           2               34   \n",
       "11048       11048          2023         1          51                6   \n",
       "\n",
       "       universite_adi  universite_turu  burslu_ise_burs_yuzdesi  \\\n",
       "0               199.0                0                        0   \n",
       "1                14.0                0                        0   \n",
       "2               179.0                1                      100   \n",
       "3               171.0                0                        0   \n",
       "4                78.0                0                        0   \n",
       "...               ...              ...                      ...   \n",
       "11044            13.0                0                        0   \n",
       "11045           180.0                0                        0   \n",
       "11046           146.0                0                        0   \n",
       "11047            50.0                0                        0   \n",
       "11048            14.0                0                        0   \n",
       "\n",
       "       burs_aliyor_mu?  bölüm  ...  anne_calisma_durumu  anne_sektor  \\\n",
       "0                    0  347.0  ...                    1            2   \n",
       "1                    0  432.0  ...                    0            0   \n",
       "2                    1   44.0  ...                    0            0   \n",
       "3                    0  228.0  ...                    0            0   \n",
       "4                    0  230.0  ...                    1            1   \n",
       "...                ...    ...  ...                  ...          ...   \n",
       "11044                0  111.0  ...                    0            0   \n",
       "11045                0  159.0  ...                    0            0   \n",
       "11046                0  104.0  ...                    0            0   \n",
       "11047                0    9.0  ...                    0            0   \n",
       "11048                0  111.0  ...                    0            0   \n",
       "\n",
       "       baba_egitim_durumu  baba_calisma_durumu  baba_sektor  kardes_sayisi  \\\n",
       "0                       2                    1            3            2.0   \n",
       "1                       1                    1            2            3.0   \n",
       "2                       4                    0            0            0.0   \n",
       "3                       3                    1            2            4.0   \n",
       "4                       4                    1            1            1.0   \n",
       "...                   ...                  ...          ...            ...   \n",
       "11044                   2                    0            0            0.0   \n",
       "11045                   1                    1            1            3.0   \n",
       "11046                   4                    1            3            2.0   \n",
       "11047                   2                    1            3            2.0   \n",
       "11048                   4                    1            2            3.0   \n",
       "\n",
       "       ingilizce_biliyor_musunuz?  ingilizce_seviyeniz?  dogum_yili  dogum_ayi  \n",
       "0                               1                   0.0        2002          6  \n",
       "1                               1                   0.0        2004          5  \n",
       "2                               1                   0.0        2002          4  \n",
       "3                               0                   0.0        2003          3  \n",
       "4                               1                   0.0        2002          1  \n",
       "...                           ...                   ...         ...        ...  \n",
       "11044                           1                   0.0        2002          1  \n",
       "11045                           0                   0.0        2001          9  \n",
       "11046                           1                   0.0        2004          6  \n",
       "11047                           1                   0.0        2001         10  \n",
       "11048                           1                   0.0        1999          9  \n",
       "\n",
       "[11049 rows x 25 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict_on_test_data(\n",
    "    best_params, best_model_name, X_train, y_train, test_data, test_ids\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>36.346371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>37.746964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>40.939720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>34.311832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>49.334766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11044</th>\n",
       "      <td>11044</td>\n",
       "      <td>36.306202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11045</th>\n",
       "      <td>11045</td>\n",
       "      <td>34.778908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11046</th>\n",
       "      <td>11046</td>\n",
       "      <td>38.024315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11047</th>\n",
       "      <td>11047</td>\n",
       "      <td>37.819725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11048</th>\n",
       "      <td>11048</td>\n",
       "      <td>41.699608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11049 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  Predictions\n",
       "0          0    36.346371\n",
       "1          1    37.746964\n",
       "2          2    40.939720\n",
       "3          3    34.311832\n",
       "4          4    49.334766\n",
       "...      ...          ...\n",
       "11044  11044    36.306202\n",
       "11045  11045    34.778908\n",
       "11046  11046    38.024315\n",
       "11047  11047    37.819725\n",
       "11048  11048    41.699608\n",
       "\n",
       "[11049 rows x 2 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11049 entries, 0 to 11048\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   id           11049 non-null  int64  \n",
      " 1   Predictions  11049 non-null  float32\n",
      "dtypes: float32(1), int64(1)\n",
      "memory usage: 129.6 KB\n"
     ]
    }
   ],
   "source": [
    "predictions.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[\"Predictions\"] = predictions[\"Predictions\"].astype(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.rename(columns={\"Predictions\": \"Degerlendirme Puani\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# Save predictions to CSV\n",
    "pd.DataFrame(predictions).to_csv(\"predictions.csv\", index=False)\n",
    "print(\"Predictions saved to predictions.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds-study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
